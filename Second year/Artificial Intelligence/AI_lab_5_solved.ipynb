{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c4555-8fd6-4597-a587-b78746d0f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed forward:\n",
    "# = a multilayer perceptron\n",
    "#where connections between units (neurons) do not form cycles\n",
    "#the information moves in only one direction: forward, from the input nodes through the hidden layers (if any) to the output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "#model1 = nn.Sequential(OrderedDict([\n",
    "#    ('hidden', nn.\n",
    "#]))\n",
    "\n",
    "#model architecture\n",
    "class AdderModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):  # we initialize the layers of the neural network\n",
    "        super(AdderModel, self).__init__()            #base class for all neural network modules in pytorch\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)      # connects the input layer to the hidden layer, input: input layer, output: hidden layer\n",
    "                                                              #bias=Trye by default\n",
    "        self.relu = nn.ReLU()                                 # we introduce non-linearity with relu activation function\n",
    "        self.output = nn.Linear(hidden_size, output_size)     #  connects the hidden layer to the output layer (another hidden layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))    #pass through relu\n",
    "        x = self.output(x)               #and to output\n",
    "        return x\n",
    "\n",
    "# models\n",
    "model1 = AdderModel(2, 4, 1)   #(input_size, hidden_units, output_size)\n",
    "model2 = AdderModel(2, 8, 1)\n",
    "model3 = AdderModel(2, 16, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdderModel(\n",
      "  (hidden): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n",
      "AdderModel(\n",
      "  (hidden): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "AdderModel(\n",
      "  (hidden): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#print(model)\n",
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)\n",
    "\n",
    "#bias allows the model to learn offsets from zero\n",
    "#helps the model to capture patterns that don't pass through the origin of the coordinate system\n",
    "#by default true in the nn.Linear function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor( ...\n",
    "#print(data_in)\n",
    "\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# data_target = torch.tensor( ...\n",
    "#print(data_target)\n",
    "\n",
    "# We prepare target data\n",
    "data_target = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# criterion = \n",
    "# optimizer = \n",
    "\n",
    "criterion = nn.MSELoss()         #Mean Squared Error  loss function\n",
    "optimizer1 = torch.optim.SGD(model1.parameters(), lr=0.01)   #optimizers: stochastic gradient descent \n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01)\n",
    "optimizer3 = torch.optim.SGD(model3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10000], Model1 Loss: 1.2716213464736938, Model2 Loss: 0.27266979217529297, Model3 Loss: 1.622287392616272\n",
      "Epoch [1001/10000], Model1 Loss: 0.0071937614120543, Model2 Loss: 0.0689520314335823, Model3 Loss: 0.028372179716825485\n",
      "Epoch [2001/10000], Model1 Loss: 6.592768477275968e-05, Model2 Loss: 0.0024212959688156843, Model3 Loss: 0.00010332101373933256\n",
      "Epoch [3001/10000], Model1 Loss: 5.995346441522997e-07, Model2 Loss: 3.187239417457022e-05, Model3 Loss: 1.4849888430035207e-07\n",
      "Epoch [4001/10000], Model1 Loss: 5.475015552036666e-09, Model2 Loss: 3.574523361749016e-07, Model3 Loss: 2.265035381476821e-10\n",
      "Epoch [5001/10000], Model1 Loss: 1.2600109844385088e-10, Model2 Loss: 3.957355332318002e-09, Model3 Loss: 2.950763244857768e-11\n",
      "Epoch [6001/10000], Model1 Loss: 7.221732239992562e-11, Model2 Loss: 1.6136003644362518e-10, Model3 Loss: 1.792749282358841e-11\n",
      "Epoch [7001/10000], Model1 Loss: 5.847094336486336e-11, Model2 Loss: 6.45128395149186e-11, Model3 Loss: 1.7894241644000886e-11\n",
      "Epoch [8001/10000], Model1 Loss: 5.111358905574015e-11, Model2 Loss: 5.723910234678442e-11, Model3 Loss: 1.792749282358841e-11\n",
      "Epoch [9001/10000], Model1 Loss: 4.6465522401950565e-11, Model2 Loss: 5.505129685445809e-11, Model3 Loss: 1.7894241644000886e-11\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Train the model\n",
    "\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    output1 = model1(data_in)\n",
    "    loss1 = criterion(output1, data_target)    #we compute the loss\n",
    "                                               #criterion quantifies how well the model is performing on the given task, \n",
    "                                               #with the goal of minimizing this discrepancy during training\n",
    "    \n",
    "    output2 = model2(data_in)\n",
    "    loss2 = criterion(output2, data_target)\n",
    "    \n",
    "    output3 = model3(data_in)\n",
    "    loss3 = criterion(output3, data_target)\n",
    "    \n",
    "    # Zero gradients, backward pass, optimize\n",
    "    optimizer1.zero_grad()     # we zero out the gradients stored in the optimizer for each model \n",
    "    loss1.backward()           # we compute the gradients of the loss with respect to the model parameters \n",
    "    optimizer1.step()          # we update the parameters of each model using the optimizer \n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss2.backward()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    optimizer3.zero_grad()\n",
    "    loss3.backward()\n",
    "    optimizer3.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Model1 Loss: {loss1.item()}, Model2 Loss: {loss2.item()}, Model3 Loss: {loss3.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Predictions:\n",
      "[0.0, 1.0, 1.0, 0.0]\n",
      "Model 2 Predictions:\n",
      "[0.0, 1.0, 1.0, 0.0]\n",
      "Model 3 Predictions:\n",
      "[0.0, 1.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# visualize the resuts\n",
    "\n",
    "# Test the models after training\n",
    "with torch.no_grad():                 #temporarily disable gradient calculation to speed up computation and reduce memory usage \n",
    "                                                     #( Since we're only interested in evaluating\n",
    "                                                     #the trained models on the test data and not in computing gradients)\n",
    "    test_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "    \n",
    "    # Model 1\n",
    "    model1.eval()                      #sets the model into evaluation mode, which disables dropout layers and gradient claculation\n",
    "                                       #disable operations that are relevant only during training\n",
    "    output1 = model1(test_data)\n",
    "    print(\"Model 1 Predictions:\")\n",
    "    print(output1.round().squeeze().tolist())\n",
    "    \n",
    "    # Model 2\n",
    "    model2.eval()\n",
    "    output2 = model2(test_data)\n",
    "    print(\"Model 2 Predictions:\")\n",
    "    print(output2.round().squeeze().tolist())\n",
    "    \n",
    "    # Model 3\n",
    "    model3.eval()\n",
    "    output3 = model3(test_data)\n",
    "    print(\"Model 3 Predictions:\")\n",
    "    print(output3.round().squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Weights:\n",
      "OrderedDict([('hidden.weight', tensor([[-0.6658,  0.9046],\n",
      "        [ 0.3929,  0.6498],\n",
      "        [-0.6235,  0.9333],\n",
      "        [ 0.9098, -0.8880]])), ('hidden.bias', tensor([-2.2240e-01,  2.8278e-01, -2.9549e-01, -1.9050e-08])), ('output.weight', tensor([[ 0.8339, -0.0464,  0.7232,  1.1192]])), ('output.bias', tensor([0.0131]))])\n",
      "Model 2 Weights:\n",
      "OrderedDict([('hidden.weight', tensor([[-0.8318, -0.8318],\n",
      "        [-0.4498, -0.2199],\n",
      "        [ 0.8835, -0.8835],\n",
      "        [-0.6110,  0.2958],\n",
      "        [ 0.9029, -0.0698],\n",
      "        [ 0.5057, -0.0887],\n",
      "        [ 0.0866,  0.2417],\n",
      "        [-0.3943,  0.4070]])), ('hidden.bias', tensor([ 8.3184e-01,  8.5437e-01,  2.2844e-06, -5.3799e-01,  6.9797e-02,\n",
      "         7.2895e-01,  4.9826e-01, -6.8456e-01])), ('output.weight', tensor([[-1.2472,  0.6733,  1.0895,  0.1626, -0.7594, -0.0597,  0.2164,  0.1059]])), ('output.bias', tensor([0.4509]))])\n",
      "Model 3 Weights:\n",
      "OrderedDict([('hidden.weight', tensor([[ 0.2040, -0.2762],\n",
      "        [ 0.5501, -0.6082],\n",
      "        [-0.7026,  0.5706],\n",
      "        [-0.3451,  0.3962],\n",
      "        [-0.1582,  0.4583],\n",
      "        [ 0.4236, -0.1208],\n",
      "        [-0.4727, -0.1844],\n",
      "        [ 0.4194,  0.8291],\n",
      "        [-0.3800, -0.1372],\n",
      "        [ 0.6138,  0.6216],\n",
      "        [-0.6381, -0.6717],\n",
      "        [-0.7844,  0.7844],\n",
      "        [ 0.3620, -0.4128],\n",
      "        [ 0.2285,  0.3782],\n",
      "        [ 0.7557, -0.1647],\n",
      "        [-0.4816,  0.2280]])), ('hidden.bias', tensor([ 4.6293e-01, -2.4182e-01,  1.3203e-01,  4.7114e-01, -6.2891e-01,\n",
      "        -5.3843e-01, -5.6051e-01, -4.1940e-01, -3.1772e-01,  6.9245e-01,\n",
      "         6.3809e-01,  6.6902e-09,  3.3931e-01,  5.0671e-01,  6.7682e-01,\n",
      "        -2.2926e-01])), ('output.weight', tensor([[ 0.2932,  0.2082,  0.6211, -0.2094, -0.2208, -0.1997, -0.0428, -0.6240,\n",
      "         -0.1507, -0.0375, -0.7708,  1.0249,  0.3255, -0.0740,  0.4182,  0.0399]])), ('output.bias', tensor([0.0428]))])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# print model weights\n",
    "\n",
    "\n",
    "print(\"Model 1 Weights:\")\n",
    "print(model1.state_dict())\n",
    "print(\"Model 2 Weights:\")\n",
    "print(model2.state_dict())\n",
    "print(\"Model 3 Weights:\")\n",
    "print(model3.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521a0171-b0d4-4768-a1d2-0bb252f9fb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Weights:\n",
      "hidden.weight tensor([[-0.6658,  0.9046],\n",
      "        [ 0.3929,  0.6498],\n",
      "        [-0.6235,  0.9333],\n",
      "        [ 0.9098, -0.8880]])\n",
      "output.weight tensor([[ 0.8339, -0.0464,  0.7232,  1.1192]])\n",
      "\n",
      "Model 2 Weights:\n",
      "hidden.weight tensor([[-0.8318, -0.8318],\n",
      "        [-0.4498, -0.2199],\n",
      "        [ 0.8835, -0.8835],\n",
      "        [-0.6110,  0.2958],\n",
      "        [ 0.9029, -0.0698],\n",
      "        [ 0.5057, -0.0887],\n",
      "        [ 0.0866,  0.2417],\n",
      "        [-0.3943,  0.4070]])\n",
      "output.weight tensor([[-1.2472,  0.6733,  1.0895,  0.1626, -0.7594, -0.0597,  0.2164,  0.1059]])\n",
      "\n",
      "Model 3 Weights:\n",
      "hidden.weight tensor([[ 0.2040, -0.2762],\n",
      "        [ 0.5501, -0.6082],\n",
      "        [-0.7026,  0.5706],\n",
      "        [-0.3451,  0.3962],\n",
      "        [-0.1582,  0.4583],\n",
      "        [ 0.4236, -0.1208],\n",
      "        [-0.4727, -0.1844],\n",
      "        [ 0.4194,  0.8291],\n",
      "        [-0.3800, -0.1372],\n",
      "        [ 0.6138,  0.6216],\n",
      "        [-0.6381, -0.6717],\n",
      "        [-0.7844,  0.7844],\n",
      "        [ 0.3620, -0.4128],\n",
      "        [ 0.2285,  0.3782],\n",
      "        [ 0.7557, -0.1647],\n",
      "        [-0.4816,  0.2280]])\n",
      "output.weight tensor([[ 0.2932,  0.2082,  0.6211, -0.2094, -0.2208, -0.1997, -0.0428, -0.6240,\n",
      "         -0.1507, -0.0375, -0.7708,  1.0249,  0.3255, -0.0740,  0.4182,  0.0399]])\n"
     ]
    }
   ],
   "source": [
    "# Print only the weights of the models\n",
    "print(\"Model 1 Weights:\")\n",
    "for name, param in model1.named_parameters():        #named_parameters  returns an iterator over all named parameters of the model\n",
    "    if 'weight' in name:\n",
    "        print(name, param.data)\n",
    "\n",
    "print(\"\\nModel 2 Weights:\")\n",
    "for name, param in model2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(name, param.data)\n",
    "\n",
    "print(\"\\nModel 3 Weights:\")\n",
    "for name, param in model3.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78a933-d3cb-41a2-be58-bd35145aa7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
